{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score,balanced_accuracy_score\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('./train.csv')\n",
    "df_1 = df_1.drop(['s53', 's54','s55','s56','s57', 's59'], axis=1)  #dropping incomplete features\n",
    "\n",
    "column_list = df_1.columns\n",
    "df_1['s52'] = df_1['s52'].replace(['l','o'],['1','0'])    #replacing syntax  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Alphanumeric data to Ascii values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting to ascii: Any character --> Corresponding ascii value\n",
    "## Any string --> summation of each character's acii v\n",
    "\n",
    "for i in column_list:\n",
    "    if i == 'id':\n",
    "        continue\n",
    "    arr = df_1[i]\n",
    "    new_arr = []\n",
    "    for each_val in arr:\n",
    "        if isinstance(each_val, str):\n",
    "            if len(each_val) > 1:\n",
    "                get_all_ascii = [ord(j) for j in each_val]\n",
    "                final_val = sum(get_all_ascii)\n",
    "                new_arr.append(final_val)\n",
    "            else:\n",
    "                new_arr.append(ord(each_val))\n",
    "\n",
    "        elif math.isnan(each_val):\n",
    "            new_arr.append(0)\n",
    "        else:\n",
    "            new_arr.append(each_val)\n",
    "    df_1[i] = np.asarray(new_arr)\n",
    "    df_1[i] = pd.to_numeric(df_1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding of Alphanumeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('./train.csv')\n",
    "df_2 = df_2.drop(['id','s53', 's54','s55','s56','s57', 's59'], axis=1)  #dropping incomplete features with ID\n",
    "\n",
    "column_list = df_2.columns\n",
    "df_2['s52'] = df_2['s52'].replace(['l','o'],['1','0'])    #replacing syntax  \n",
    "\n",
    "\n",
    "categorical_features = ['gender', 's11', 's12', 's16', 's17', 's18', 's58','s69','s71','s70']\n",
    "\n",
    "for i in categorical_features :\n",
    "# get the dummies and store it in a variable\n",
    "    dummies = pd.get_dummies(df_1[i])\n",
    "    df_2 = pd.concat([df_2, dummies], axis='columns')   #one hot encoding of all alphanumeric data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.drop(categorical_features, axis=1)\n",
    "\n",
    "df_2.columns = ['s13', 's48', 's52', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8',\n",
    "       'n9', 'n10', 'n11', 'n12', 'n13', 'n14', 'n15','label', 'F', 'M', 'N', 'Y', 'N_1',\n",
    "       'Y_1', 'A', 'B', 'C', 'D', 'A_1', 'B_1', 'C_1', 'D_1', 'A_2', 'B_2', 'C_2', 'D_2', 'A_3',\n",
    "       'B_3', '0', 'C_3', 'x', '~1', 'a', 'b', 'c', 'd', 'op: A', 'op: B',\n",
    "       'op: C', 'op: D']\n",
    "\n",
    "column_list = df_2.columns\n",
    "\n",
    "for i in column_list:\n",
    "    df_2[i] = pd.to_numeric(df_2[i])\n",
    "    \n",
    "df_2 = df_2.reset_index()\n",
    "df_2 = df_2.drop('index', axis = 1)\n",
    "df_2['id'] = df_1['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging two types of processed alphanumeric data(One hot encoded,ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.merge(df_2, df_1[['id','gender','s11','s12','s16','s17','s18','s58','s69','s70','s71']], on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['s13', 's48', 's52', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8',\n",
       "       'n9', 'n10', 'n11', 'n12', 'n13', 'n14', 'n15', 'label', 'F', 'M', 'N',\n",
       "       'Y', 'N_1', 'Y_1', 'A', 'B', 'C', 'D', 'A_1', 'B_1', 'C_1', 'D_1',\n",
       "       'A_2', 'B_2', 'C_2', 'D_2', 'A_3', 'B_3', '0', 'C_3', 'x', '~1', 'a',\n",
       "       'b', 'c', 'd', 'op: A', 'op: B', 'op: C', 'op: D', 'id', 'gender',\n",
       "       's11', 's12', 's16', 's17', 's18', 's58', 's69', 's70', 's71'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset saving (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv('./processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_3.drop(['id','label'], axis=1)\n",
    "y = df_3['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training (Xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-65484b1b8dad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                       \u001b[0mreg_alpha\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m87.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                       reg_lambda= 0.08809142885491292,scale_pos_weight = 6,n_estimators=10000)#\"gain\", \"weight\", \"cover\"\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "\n",
    "model = XGBClassifier(learning_rate=0.001,\n",
    "                      colsample_bytree = 0.8104161212923376,\n",
    "                      gamma= 2.443119529076133, \n",
    "                      max_depth= 7, \n",
    "                      min_child_weight= 7, \n",
    "                      reg_alpha= 87.0,\n",
    "                      reg_lambda= 0.08809142885491292,scale_pos_weight = 6,n_estimators=10000)#\"gain\", \"weight\", \"cover\"\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Hyperparameter Tuning (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier(scale_pos_weight = 6,\n",
    "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, pred>0.5)\n",
    "    print (\"SCORE:\", balanced_accuracy)\n",
    "    return {'loss': -balanced_accuracy, 'status': hyperopt.STATUS_OK }\n",
    "\n",
    "\n",
    "trials = hyperopt.Trials()\n",
    "\n",
    "best_hyperparams = hyperopt.fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = hyperopt.tpe.suggest,\n",
    "                        max_evals = 300,\n",
    "                        trials = trials)\n",
    "\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Score showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_v_xgb = model.predict(X_test)    #predicting values on test data(val set)\n",
    "y_pred_v_xgb = [round(value) for value in y_pred_v_xgb]   #rounding floating values\n",
    "accuracy = accuracy_score(y_test, y_pred_v_xgb)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(f' test f1 {f1_score(y_test, y_pred_v_xgb)}')\n",
    "print(f' test balance acc {balanced_accuracy_score(y_test, y_pred_v_xgb)}')   #balanced accuracy matches with leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testset csv generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alphanumeric to ascii value\n",
    "\n",
    "df_1 = pd.read_csv('./test.csv')\n",
    "df_1 = df_1.drop(['s53', 's54','s55','s56','s57', 's59'], axis=1)  #dropping incomplete features\n",
    "\n",
    "column_list = df_1.columns\n",
    "df_1['s52'] = df_1['s52'].replace(['l','o'],['1','0'])    #replacing syntax  \n",
    "\n",
    "## Converting to ascii: Any character --> Corresponding ascii value\n",
    "## Any string --> summation of each character's acii v\n",
    "\n",
    "for i in column_list:\n",
    "    if i == 'id':\n",
    "        continue\n",
    "    arr = df_1[i]\n",
    "    new_arr = []\n",
    "    for each_val in arr:\n",
    "        if isinstance(each_val, str):\n",
    "            if len(each_val) > 1:\n",
    "                get_all_ascii = [ord(j) for j in each_val]\n",
    "                final_val = sum(get_all_ascii)\n",
    "                new_arr.append(final_val)\n",
    "            else:\n",
    "                new_arr.append(ord(each_val))\n",
    "\n",
    "        elif math.isnan(each_val):\n",
    "            new_arr.append(0)\n",
    "        else:\n",
    "            new_arr.append(each_val)\n",
    "    df_1[i] = np.asarray(new_arr)\n",
    "    df_1[i] = pd.to_numeric(df_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alphanumeric to one hot encoded value\n",
    "\n",
    "df_2 = pd.read_csv('./test.csv')\n",
    "df_2 = df_2.drop(['id','s53', 's54','s55','s56','s57', 's59'], axis=1)  #dropping incomplete features with ID\n",
    "\n",
    "column_list = df_2.columns\n",
    "df_2['s52'] = df_2['s52'].replace(['l','o'],['1','0'])    #replacing syntax  \n",
    "\n",
    "\n",
    "categorical_features = ['gender', 's11', 's12', 's16', 's17', 's18', 's58','s69','s71','s70']\n",
    "\n",
    "for i in categorical_features :\n",
    "# get the dummies and store it in a variable\n",
    "    dummies = pd.get_dummies(df_1[i])\n",
    "    df_2 = pd.concat([df_2, dummies], axis='columns')   #one hot encoding of all alphanumeric data\n",
    "    \n",
    "\n",
    "df_2 = df_2.drop(categorical_features, axis=1)\n",
    "\n",
    "df_2.columns = ['s13', 's48', 's52', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8',\n",
    "       'n9', 'n10', 'n11', 'n12', 'n13', 'n14', 'n15','label', 'F', 'M', 'N', 'Y', 'N_1',\n",
    "       'Y_1', 'A', 'B', 'C', 'D', 'A_1', 'B_1', 'C_1', 'D_1', 'A_2', 'B_2', 'C_2', 'D_2', 'A_3',\n",
    "       'B_3', '0', 'C_3', 'x', '~1', 'a', 'b', 'c', 'd', 'op: A', 'op: B',\n",
    "       'op: C', 'op: D']\n",
    "\n",
    "column_list = df_2.columns\n",
    "\n",
    "for i in column_list:\n",
    "    df_2[i] = pd.to_numeric(df_2[i])\n",
    "    \n",
    "df_2 = df_2.reset_index()\n",
    "df_2 = df_2.drop('index', axis = 1)\n",
    "df_2['id'] = df_1['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging both converted data\n",
    "df_3 = pd.merge(df_2, df_1[['id','gender','s11','s12','s16','s17','s18','s58','s69','s70','s71']], on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating testing X\n",
    "X = df_3.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = df_3['id']\n",
    "sub['label'] = y_pred\n",
    "\n",
    "sub.to_csv('submission.csv',index = False)   #saving csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
